{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"20\">Geospatial Analysis & Visualization w/ Python</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0) Setup\n",
    "* To get started, we need to import all our packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1) Importing our data\n",
    "* We'll load the Police Killing Data as a \"DataFrame\" using pandas\n",
    "\n",
    "\n",
    "* Then we'll convert it into a \"GeoDataFrame\" using Geopandas\n",
    "    * To do this, we must assign the \"geometry\".  In this case its point data, and the coordinates are in lat/long\n",
    "    \n",
    "    \n",
    "* Then we need to assign a Coordiante Reference System (CRS) manually\n",
    "    * ESPG is a standardized code that is used to represent CRSs.\n",
    "    * 'espg:4326' is for the refers to the WGS 1984 datum, which our latitude/longitude data is based in.\n",
    "        * This is a CRS that is widely used by many web-based platforms because like Google Maps and Mapbox\n",
    "        * The original only had addresses, not coordinates, so we used a webservice (Mapbox) to generate the coordinates of our addresses\n",
    "        \n",
    "        \n",
    "* Once we have the data loaded, calling .head() will give us a \"preview\" of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the Police Killings file, and set the incident ID as the index\n",
    "police_Killings_Tabular = pd.read_csv('Data/PoliceKillings.csv',\n",
    "                                      parse_dates=['date'],\n",
    "                                      index_col=['id_incident']\n",
    "                                     )\n",
    "\n",
    "# We can then convert the pandas dataframe into a geopandas \"GeodataFrame\"\n",
    "police_Killings = gpd.GeoDataFrame(police_Killings_Tabular,\n",
    "    geometry=gpd.points_from_xy(police_Killings_Tabular.longitude,\n",
    "                                police_Killings_Tabular.latitude\n",
    "                               )\n",
    "                                  )\n",
    "\n",
    "# Now we can assign a CRS\n",
    "WGS_1984={'init' :'epsg:4326'}\n",
    "police_Killings.crs = WGS_1984\n",
    "\n",
    "# Lets sort the incidents by date and then take a quick look.\n",
    "police_Killings=police_Killings.sort_values(by='date')\n",
    "police_Killings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll load some data from the 2016 Census\n",
    "\n",
    "* We have a tabular dataset of population data.  We'll load that using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll import the tabualr census data with pandas\n",
    "Census_Tabular = pd.read_csv('Data/Census.csv',index_col=['PRUID'])\n",
    "Census_Tabular.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We also have a provincial boundary shapefile that we can load with geopandas.\n",
    "    * Shapefile are used to store georphric data.  They already have projections and coordiantes associated with them.\n",
    "    * Geopandas has similar functionality to pandas.  But the read_file() method had less options, so we have to set the index manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll import provincial boundaries using geopandas\n",
    "Provincial_Boundaries = gpd.read_file('Data/Provincial_Boundaries.shp').set_index('PRUID')\n",
    "Provincial_Boundaries.head()\n",
    "# Provincial_Boundaries = Provincial_Boundaries.drop(['PRENAME','PRFNAME','PREABBR','PRFABBR','AREA_LCC','AREA_AEA','Area_Merc'],axis=1)\n",
    "# Provincial_Boundaries.geometry = Provincial_Boundaries.simplify(100)\n",
    "# Provincial_Boundaries.to_file('Data/Provincial_Boundaries.shp')\n",
    "# Provincial_Boundaries.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2) Joining our census data\n",
    "\n",
    "* This will let us map the disparity by province and do a more detailed analysis\n",
    "\n",
    "* PRUID is a \"unique identifier\" that represents the provinces.\n",
    "\n",
    "    * Since both have the PRUID set as the index, we don't need to specify a join key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Test_Join = Provincial_Boundaries.join(Census_Tabular)\n",
    "Test_Join.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But our join fails :(\n",
    "\n",
    "* ## Notice the NaN values\n",
    "\n",
    "* Wonder Why?\n",
    "    * Lets look at the index for both files?  Maybe we have a datatype missmatch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Provincial_Boundaries.index.dtype)\n",
    "print(Census_Tabular.index.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sure enough!  The Provincial_Boundaries index is an \"object\", not an integer.\n",
    "\n",
    "* We can fix that easily and then do the join!\n",
    "    * We just need to change the datatype of the Provincial_Boundaries layer.\n",
    "\n",
    "### How could we do this?\n",
    "* Hint The anser is in the cell above!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = \n",
    "Provincial_Boundaries.index = Provincial_Boundaries.index.astype(dtype)\n",
    "Provincial_Boundaries = Provincial_Boundaries.join(Census_Tabular)\n",
    "Provincial_Boundaries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3) Exploring the data\n",
    "\n",
    "### First lets make a quick map.\n",
    "\n",
    "* Our Layers need to be in the same coordinate system to match up properly on a map!\n",
    "\n",
    "* We can re-project the police_Killings layer using the .to_crs function to set the CRS to that of the Provinces\n",
    "    * The provinces layer uses the Canada Lambert Conformal Conic projection (LCC).  This is the standard projection used by stats canada and is ideally suited for displaying the whole of country.\n",
    "        \n",
    "        \n",
    "* Once both datasets are in the same coordinate system, we can make a map!\n",
    "\n",
    "\n",
    "* First we must define a plot, using the matplotlib.pyplot package.  We imported this earlier as \"plt\"\n",
    "    * We use the plt.subplots() to create a figure, and we can define how big we want it to be\n",
    "    \n",
    "    \n",
    "* Geoapandas can then use the .plot() fucntion to create a map using matplotlib.\n",
    "    * We simply tell it what axis to draw the plot on with ax=\"axes\"\n",
    "    * Then set a few other parameters:\n",
    "        * We just want the provinces as a grey background so we can set the color\n",
    "        * We want to classify killings by race, so we can set race as the column.  THen we can add a legend to aid interpretation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We can use .to_crs() to create a police killings layer with the same projection as the provinces layer.\n",
    "police_Killings = police_Killings.to_crs(Provincial_Boundaries.crs)\n",
    "\n",
    "# Now, we can create a figure using matplotlib (plt), first we define the figure and the size\n",
    "fig,axes=plt.subplots(\n",
    "    figsize=(6,6)\n",
    ")\n",
    "\n",
    "# Now we can add the provinces using the .plot() function.  We set the plotting axes and give it a grey color\n",
    "cb = Provincial_Boundaries.plot(\n",
    "    ax=axes,\n",
    "#     alpha=.5,\n",
    "    column='Total',\n",
    "    cmap = 'Greys',\n",
    "    edgecolor='grey',\n",
    "    legend=True,\n",
    ")\n",
    "\n",
    "# Then we add the police_Killings_LCC.  We'll set the column to 'race', so we can disply by race,\n",
    "# give the point markers a few more parameters, and add them to a legend\n",
    "police_Killings.plot(\n",
    "    ax=axes,\n",
    "    column='race',\n",
    "    edgecolor='k',\n",
    "    markersize=15,\n",
    "    legend=True,\n",
    "    legend_kwds={'loc': 'upper right','fontsize':8}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now you've made your first map with python!\n",
    "\n",
    "* But its an ugly map :(\n",
    "    * It doesn't look great.  This is just the quick and dirty way to look ata data\n",
    "    * To make things more presentable, we'll have to be more explicit in setting up our map.  But that's a task for later.\n",
    "\n",
    "\n",
    "### For now, lets move on and look at the dataset in more detail.\n",
    "\n",
    "* Pandas & Geopandas have some nice features to quickly summarize our dataset.\n",
    "\n",
    "\n",
    "\n",
    "* We can use .count() to get the total # incidents.\n",
    "    * Callling .count() as is, will give us a list of all the columns, and a count for each.  We can see most collumns are \"full\" but in the \"geocoding_Notes\" column, we can see that 4 points don't have coordinates associated with their address.  This suggests there was an error in the data entry process.  We don't need to worry about this though.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_Killings.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can use .mean(), .min(), etc. followed by ['age'] to get some vital statistics on the age of victims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Age Distribution of Victims')\n",
    "print()\n",
    "print('Mean:                ',\n",
    "      police_Killings.mean()['age']\n",
    "     )\n",
    "print()\n",
    "print('Standard Deviation:  ',\n",
    "      police_Killings.std()['age']\n",
    "     )\n",
    "print()\n",
    "print('Youngest:            ',\n",
    "      police_Killings.max()['age']\n",
    "     )\n",
    "print()\n",
    "print('Oldest:              ',\n",
    "      police_Killings.min()['age']\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can resample our data to look for trends\n",
    "* The date column is a special type of data that allows us to resample our data by year, month, etc\n",
    "* The dataset has to be in order by date for this to work (we did this alread)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Resampled = police_Killings.set_index('date').resample('Y').count()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(\n",
    "    Resampled.index.year,\n",
    "    Resampled['id_victim'],\n",
    "    edgecolor='black',\n",
    "    facecolor='#FF0000'\n",
    ")\n",
    "plt.title('Police Killings per Year in Canda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can group our data to look for patterns too.\n",
    "\n",
    "* the .groupby() function can accept one or multple paramters to group our dataset by.\n",
    "    * This allows us to create complex queries if we want.\n",
    "* We can have to follow up with .count(), .mean(), etc.\n",
    "    * This tells us \"how\" to aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(9,6))\n",
    "\n",
    "\n",
    "Armed = police_Killings.groupby(['armed_type']).count()\n",
    "ax.pie(\n",
    "    Armed['id_victim'],\n",
    "    labels=Armed.index,\n",
    "    textprops={'fontsize': 8},\n",
    "    autopct='%1.1f%%',\n",
    "    wedgeprops={\"edgecolor\":\"k\",'linewidth': 1, 'linestyle': 'dashed'}\n",
    ")\n",
    "ax.set_title('Police Killings: Was the Victim Armed?')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_Killings.groupby(['gender','mentral_distress_disorder']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We're intersted in a specific question.  What's the distribution of police killings by race?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_Killings.groupby(['race']).count()['date'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4) Normalizing our Data\n",
    "\n",
    "* The racial demographics of Canada aren't evenly split however!\n",
    "\n",
    "* We need to Normalize our data by population statistics.\n",
    "\n",
    "* Lets look at our census data again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Provincial_Boundaries[Census_Tabular.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first row contains the total values for the whole country.  We can use this to calculate a police killing rate.\n",
    "\n",
    "* But the Canadian Census' racial categories don't match up perfectly with the police violence dataset's racial\n",
    "* How can we work around this?\n",
    "    * We have the largest three groups in the police killing set: White, Indigenous, and Black.  So we can work with them as is\n",
    "    * The other races make up a small portion of total killings.  And we can't be entirely sure how the CBC defined their groupings.  So, lets add a new category: \"Other Minorities\"\n",
    "    \n",
    "* We'll do this for both the provincial boundaires and the police_Killings\n",
    "    * For the police killings, we'll leave the unknow records alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Other_Minorities=['South Asian', 'Chinese', 'Filipino','Latin American',\n",
    " 'Arab', 'Southeast Asian', 'West Asian', 'Korean',\n",
    "'Japansese', 'Visible minority, n.i.e', 'Mixed']\n",
    "Provincial_Boundaries['Other Minorities']=Provincial_Boundaries[Other_Minorities].sum(axis=1)\n",
    "\n",
    "Other_Minorities=['Latin American', 'Arab', 'Other', 'South Asian', 'Asian']\n",
    "police_Killings['race'] = police_Killings['race'].replace(to_replace=Other_Minorities,value='Other Minorities')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From here, we can calculate the police killing rate.\n",
    "\n",
    "* Dividing the total number of killings by the population gives us ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Races = ['Indigenous','Black','Caucasian','Other Minorities']\n",
    "Race_Breakdown = police_Killings.groupby(['race']).count()['id_victim']\n",
    "Can_Pop = Provincial_Boundaries[Races].sum()\n",
    "\n",
    "Racial_Rates = Race_Breakdown.T[Races]/Can_Pop\n",
    "Racial_Rates['Average']=Race_Breakdown.T[Races].sum()/Can_Pop.sum()\n",
    "print(Racial_Rates)\n",
    "# police_Killings.groupby(['race']).count()['date'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This number isn't that meaningful though.  It represents the number of killings \"per person\" over the whole study period.\n",
    "\n",
    "* Lets convert the rate to a more meaninful unit.  Killings / Million Residents / Year\n",
    "\n",
    "* The date record is a \"date\" object.\n",
    "* It has some added functionality like being able to query the the year, month, day\n",
    "\n",
    "### How might we use calculate our police killing rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "First_Year = police_Killings['date'].min().year\n",
    "Last_Year = police_Killings['date'].max().year\n",
    "print(First_Year,Last_Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Scale = \n",
    "Duration = \n",
    "rate_Conversion = Scale / Duration\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (7,6))\n",
    "ax.barh(\n",
    "    Racial_Rates.index,\n",
    "    Racial_Rates.values * rate_Conversion,\n",
    "    facecolor='#FF0000',\n",
    "    edgecolor='black',\n",
    "    linewidth=1\n",
    ")\n",
    "ax.set_title('Police Killings by Race in Canada')\n",
    "ax.set_xlabel('Killings/Million Residents/Year')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Police killing rates are 5x higher for Indigenous people and 4x higher for Black people than it is fo White people.\n",
    "\n",
    "* This is an abhorent example of systemic racism in Canadian Policing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we  want to normalize by provincial demographics.\n",
    "\n",
    "* We have a few more steps to go through first.\n",
    "    * The police killings and census data use different abbreviations.  To do a join our dataset with the census data we'll need to assign an new abbreviaton\n",
    "    * We'll us a dictionary to do this\n",
    "    \n",
    "    \n",
    "* Then we can summarize the killings by province and join it to the Provinces_Join layer\n",
    "\n",
    "* Now we can summarize the killings by province and join it to the Provinces_Join layer\n",
    "\n",
    "\n",
    "* Note Prince Edward Island doesn't have any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "race_by_Province = police_Killings.groupby(['prov','race']).count()\n",
    "race_by_Province = race_by_Province['date'].unstack()\n",
    "race_by_Province['Total'] = race_by_Province.sum(axis=1)\n",
    "\n",
    "\n",
    "for col in Races:\n",
    "    Provincial_Boundaries = Provincial_Boundaries.join(race_by_Province[col],on='prov',rsuffix='_Killings')\n",
    "\n",
    "for col in ['Unknown','Total']:\n",
    "    Provincial_Boundaries = Provincial_Boundaries.join(race_by_Province[col],on='prov',rsuffix='_Killings')\n",
    "Provincial_Boundaries\n",
    "\n",
    "# Some provines/groups don't have any records.  Those are given NaN values, and need to be repalced with zeros\n",
    "Provincial_Boundaries[[x+'_Killings' for x in Races]]=Provincial_Boundaries[[x+'_Killings' for x in Races]].fillna(0)\n",
    "Provincial_Boundaries['Total_Killings']=Provincial_Boundaries['Total_Killings'].fillna(0)\n",
    "Provincial_Boundaries[['Unknown' for x in Races]].fillna(0)\n",
    "\n",
    "Provincial_Boundaries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5) Calcualte the police killing rate (PKR) on the provincial level\n",
    "* Nunavut has a huge problem.  Its not a conicidence that the population is 75% Inuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Provincial_Boundaries['PKR']=(Provincial_Boundaries['Total_Killings']/Provincial_Boundaries['Total']*rate_Conversion).round(2)\n",
    "\n",
    "Provincial_Boundaries.plot(column='PKR',legend=True,scheme='naturalbreaks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6) Calculate a Police Killings Discrimination Index:\n",
    "\n",
    "* For this, we'll compare the rates of police killings of black and indigenous people to white people\n",
    "\n",
    "* We'll use the following equations:\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\ Wr & = (\\frac{White Killings}{White Population}) * Rate Conversion\\\\\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\ BIr & = (\\frac{Black Killings + Indigenous Killings}{Black Population + Indigenous Population}) * Rate Conversion\\\\\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\ PKDI & = BIr - Wr\\\\\n",
    "\\end{align}\n",
    "\n",
    "* This will hightlight the disparities in police killings\n",
    "    * We'll classify the data using the following scheme:\n",
    "    \n",
    "        * \"Slight Bias\": -0.483293 to 0.483293 - This is the rate killings of whites.  Within these ranges, differences might be due to presence or lacktherof of a certain groups \n",
    "        * \"Moderate Bias\": 0.48 to 0.77 - Greater than the white rate, less than the national average\n",
    "        * \"Severe Bias\": 0.77 to 2.31 - Greater than the national rate, less than the indigenouos rate\n",
    "        * \"Extreme Bias: 2.31 to 10 - Greater than the national indigenous rate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Provincial_Boundaries['Wr']=Provincial_Boundaries['Caucasian_Killings']/Provincial_Boundaries['Caucasian']*rate_Conversion\n",
    "Provincial_Boundaries['BIr']=(Provincial_Boundaries['Indigenous_Killings']+Provincial_Boundaries['Black_Killings'])/(Provincial_Boundaries['Indigenous']+Provincial_Boundaries['Black'])*rate_Conversion\n",
    "\n",
    "Provincial_Boundaries['PKDI'] = Provincial_Boundaries['BIr'] - Provincial_Boundaries['Wr']\n",
    "\n",
    "Provincial_Boundaries['PKDI']=Provincial_Boundaries['PKDI'].fillna(0)\n",
    "\n",
    "\n",
    "bins = [-0.48,0.48,0.77,2.31,10.0]\n",
    "labels = ['Minimal Biaias','Moderate Bias','Severe Bias','Extreme Bias']\n",
    "Provincial_Boundaries['PKDI_Classes']=(pd.cut(Provincial_Boundaries['PKDI'],bins=bins,labels=labels)).astype('str')\n",
    "\n",
    "Provincial_Boundaries.round(2)\n",
    "\n",
    "# print(Provincial_Boundaries[['prov','PKDI','PKDI_Classes']].sort_values(by='PKDI').round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets map the patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Provincial_Boundaries.plot(column='PKDI_Classes',legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7) Create a detailed infographic on police violence in Canada\n",
    "\n",
    "* Matplotlib alows us to be very specific in determining our layout with gridspec.\n",
    "\n",
    "\n",
    "* We can create a large plot and define specifically what we want.\n",
    "\n",
    "\n",
    "* We'll have two maps, showing the PKR and the PKDI on the left\n",
    "\n",
    "\n",
    "* Then we'll add some smaller plots on the right showing the annual trend, national PKR by race, and some pie charts\n",
    "\n",
    "\n",
    "* We can set our default ontsize for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 16\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "\n",
    "gs = fig.add_gridspec(100,100)\n",
    "\n",
    "PKR_Map = fig.add_subplot(gs[0:45 , 0:50])\n",
    "PKDI_Map = fig.add_subplot(gs[50:95, 0:50])\n",
    "\n",
    "SourceStatement = fig.add_subplot(gs[95:, 0:50])\n",
    "\n",
    "Annual_Trend = fig.add_subplot(gs[0:20, 65:])\n",
    "PKR_national = fig.add_subplot(gs[28:48, 65:])\n",
    "Pie_1 = fig.add_subplot(gs[58:78, 65:])\n",
    "Pie_2 = fig.add_subplot(gs[80:100, 65:])\n",
    "\n",
    "\n",
    "plt.suptitle('Police Killings in Canada (2000-2017)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can add things to the figure\n",
    "* First lets do the maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Provincial_Boundaries.plot(ax=PKR_Map,\n",
    "                           column='PKR',\n",
    "                           legend=True,\n",
    "                           cmap = 'Reds',\n",
    "                           edgecolor='black',\n",
    "                           scheme='naturalbreaks')\n",
    "PKR_Map.get_legend().set_title('PKR') \n",
    "PKR_Map.get_xaxis().set_visible(False)\n",
    "PKR_Map.get_yaxis().set_visible(False)\n",
    "PKR_Map.set_title('Police Killing Rate')\n",
    "\n",
    "\n",
    "Provincial_Boundaries=Provincial_Boundaries.sort_values(by='PKDI')\n",
    "Provincial_Boundaries.plot(ax=PKDI_Map,\n",
    "                           column='PKDI',\n",
    "                           legend=True,\n",
    "                           edgecolor='black',\n",
    "                           cmap = 'Reds',\n",
    "                           scheme='naturalbreaks')\n",
    "\n",
    "# PKDI_Map.get_legend().set_bbox_to_anchor((1,0.5))\n",
    "PKDI_Map.get_legend().set_title('PKDI') \n",
    "PKDI_Map.get_xaxis().set_visible(False)\n",
    "PKDI_Map.get_yaxis().set_visible(False)\n",
    "PKDI_Map.set_title('Police Killing Discrimination Index')\n",
    "\n",
    "\n",
    "Annual_Trend.bar(\n",
    "    Resampled.index.year,\n",
    "    Resampled['id_victim'],\n",
    "    edgecolor='black',\n",
    "    facecolor='#FF0000'\n",
    ")\n",
    "Annual_Trend.set_title('Killings per Year')\n",
    "Annual_Trend.set_xticks([2000,2005,2010,2015])\n",
    "\n",
    "\n",
    "PKR_national.barh(\n",
    "    Racial_Rates.index,\n",
    "    Racial_Rates.values * rate_Conversion,\n",
    "    facecolor='#FF0000',\n",
    "    edgecolor='black',\n",
    "    linewidth=1\n",
    ")\n",
    "PKR_national.set_title('Killings by Race in')\n",
    "PKR_national.set_xlabel('Killings/Million Residents/Year')\n",
    "\n",
    "\n",
    "\n",
    "Armed = police_Killings.groupby(['armed_type']).count()\n",
    "Pie_1.pie(\n",
    "    Armed['id_victim'],\n",
    "    labels=Armed.index,\n",
    "    textprops={'fontsize': 8},\n",
    "    autopct='%1.1f%%',\n",
    "    wedgeprops={\"edgecolor\":\"k\",'linewidth': 1, 'linestyle': 'dashed'}\n",
    ")\n",
    "Pie_1.set_title('Was the Victim Armed?')\n",
    "# plt.tight_layout()\n",
    "\n",
    "\n",
    "COD = police_Killings.groupby(['Charges']).count()\n",
    "Pie_2.pie(\n",
    "    COD['id_victim'],\n",
    "    labels=COD.index,\n",
    "    textprops={'fontsize': 8},\n",
    "    autopct='%1.1f%%',\n",
    "    wedgeprops={\"edgecolor\":\"k\",'linewidth': 1, 'linestyle': 'dashed'}\n",
    ")\n",
    "Pie_2.set_title('Were Officers Charged?')\n",
    "\n",
    "\n",
    "\n",
    "DataSource='Created by June Skeeter\\nPolice Killing data collected by the CBC\\nDemographics data is from Stats Canada'\n",
    "\n",
    "SourceStatement.set_axis_off()\n",
    "SourceStatement.text(0, 0.5, \n",
    "                     DataSource,\n",
    "                     horizontalalignment='left',\n",
    "                     verticalalignment='center',\n",
    "#                      transform=ax.transAxes\n",
    "                    )\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.savefig('InfoGraphic.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the data so we can use it in the future\n",
    "* We're going to save it as a shapefile for use with geopandas or a desktop GIS\n",
    "* We're also going to save it as a \"GeoJSON\" file.  This datatype is well suited for webmapping.  Which I cover in a dfferent workshp!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Provincial_Boundaries.to_file('Data/Provincial_Police_Violence.shp')\n",
    "Provincial_Boundaries = Provincial_Boundaries.to_crs('epsg:4326')\n",
    "Provincial_Boundaries.to_file(\"Data/Provincial_Police_Violence.json\", driver = \"GeoJSON\")\n",
    "\n",
    "# police_Killings = police_Killings.to_crs('epsg:4326')\n",
    "# Temp=police_Killings[['prov','race','armed_type','age','mentral_distress_disorder','geometry']]\n",
    "# print(Temp.head())\n",
    "# Temp.to_file(\"Data/PoliceKillings.json\", driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "* Maybe Chi Square\n",
    "\n",
    "* Update legend labels\n",
    "\n",
    "* Make Infographic taller\n",
    "\n",
    "* Add Wr and BIr\n",
    "    * Add explanation of PKDI\n",
    "    \n",
    "* Update pie chart color scheme\n",
    "\n",
    "* Add info on Police Deparments"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "Armed = police_Killings.groupby(['race','armed_type']).count()['date'].unstack().fillna(0)#/\\\n",
    "# (Armed.T/Armed.sum(axis=1))[['Caucasian','Black','Indigenous']]\n",
    "Observed = Armed.T[['Caucasian','Black','Indigenous']]\n",
    "\n",
    "Expected = Observed.copy()\n",
    "\n",
    "Expected = Armed.T.sum(axis=1).values[:,np.newaxis]*\\\n",
    "       Can_Pop[['Caucasian','Black','Indigenous']].values/Can_Pop['Total'].values\n",
    "\n",
    "police_Killings.groupby('race').count()['date'].values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# police_Killings.groupby('immigrant_refugee_naturalized').count()\n",
    "print(Expected)\n",
    "\n",
    "print(Observed)\n",
    "\n",
    "print(scipy.stats.chisquare(Observed,Expected))\n",
    "\n",
    "Yearly=police_Killings.set_index('date').resample('Y').count()\n",
    "# print(Yearly)\n",
    "\n",
    "reg=scipy.stats.linregress(Yearly.index.year,Yearly.race)\n",
    "# plt.figure()\n",
    "ax2.bar(Yearly.index.year,Yearly.race,edgecolor='k')\n",
    "print(reg)\n",
    "ax2.plot(Yearly.index.year,Yearly.index.year*reg.slope+reg.intercept,color='k',\n",
    "         label = 'Slope = '+str(np.round(reg.slope,2))+' Killings per Year '\\\n",
    "        ' P = '+str(np.round(reg.pvalue,2)))\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
